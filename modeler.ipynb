{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitenv3206f7551eaf4ab3b1d866b11f23a5c8",
   "display_name": "Python 3.7.0 64-bit ('env')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Topic Modeler\n",
    "Discovering abstract topics in documents (Flipgrid Topics). Using Latent Dirichlet Allocation (LDA)we will look for relevant collections of words, or topics, in the corpus.\n",
    "\n",
    "#### Packages\n",
    "* spaCy (NLP)\n",
    "* Gensim (Topic modeling library)\n",
    "* Numpy (Math stuff)\n",
    "* Pandas (Data analysis)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "source": [
    "## Cleaning the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatizer(doc):\n",
    "    # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "    # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)\n",
    "    \n",
    "def remove_stopwords(doc):\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc\n",
    "\n",
    "# The add_pipe function appends our functions to the default pipeline.\n",
    "nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)\n",
    "\n",
    "doc = nlp('''The US government has no evidence that any foreign power has tampered with the vote count, the Department of Homeland Security's top cyber-official has said.\n",
    "\n",
    "Christopher Krebs said in a statement that there was \"no evidence any foreign adversary was capable of preventing Americans from voting or changing vote tallies\".\n",
    "\n",
    "US intelligence agencies concluded that in 2016 Russia was behind an effort to tip the scale of the US election against Hillary Clinton.\n",
    "\n",
    "\"We will remain vigilant for any attempts by foreign actors to target or disrupt the ongoing vote counting and final certification of results,\" Mr Krebs said.\n",
    "\n",
    "\"The American people are the last line of defence against foreign influence efforts and we encourage continued patience in the coming days and weeks.\"\n",
    "\n",
    "President Trump's team has filed legal action in several states. Hours after the polls closed on Tuesday evening, he alleged there was \"a fraud on the American public\" but has not offered any evidence.''')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "doc_list.append(doc)\n",
    "words = corpora.Dictionary(doc_list)\n",
    "\n",
    "# Turns each document into a bag of words.\n",
    "corpus = [words.doc2bow(doc) for doc in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=2,\n",
    "                                           update_every=1,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0,\n  '0.014*\"evidence\" + 0.014*\"vote\" + 0.014*\"\\n'\n  '\\n'\n  ' \" + 0.014*\"foreign\" + 0.014*\"line\" + 0.014*\"american\" + '\n  '0.014*\"certification\" + 0.014*\"encourage\" + 0.014*\"adversary\" + '\n  '0.014*\"ongoing\"'),\n (1,\n  '0.015*\"\\n'\n  '\\n'\n  ' \" + 0.015*\"evidence\" + 0.015*\"vote\" + 0.014*\"foreign\" + 0.014*\"american\" + '\n  '0.014*\"Krebs\" + 0.014*\"effort\" + 0.014*\"line\" + 0.014*\"ongoing\" + '\n  '0.014*\"election\"'),\n (2,\n  '0.014*\"foreign\" + 0.014*\"\\n'\n  '\\n'\n  ' \" + 0.014*\"evidence\" + 0.014*\"vote\" + 0.014*\"american\" + 0.014*\"encourage\" '\n  '+ 0.014*\"official\" + 0.014*\"effort\" + 0.014*\"Krebs\" + 0.014*\"prevent\"'),\n (3,\n  '0.054*\"\\n'\n  '\\n'\n  ' \" + 0.044*\"foreign\" + 0.044*\"vote\" + 0.033*\"evidence\" + 0.022*\"Krebs\" + '\n  '0.022*\"effort\" + 0.022*\"american\" + 0.012*\"scale\" + 0.012*\"team\" + '\n  '0.012*\"Homeland\"'),\n (4,\n  '0.014*\"vote\" + 0.014*\"\\n'\n  '\\n'\n  ' \" + 0.014*\"foreign\" + 0.014*\"evening\" + 0.014*\"ongoing\" + 0.014*\"american\" '\n  '+ 0.014*\"certification\" + 0.014*\"actor\" + 0.014*\"tally\" + 0.014*\"evidence\"'),\n (5,\n  '0.014*\"\\n'\n  '\\n'\n  ' \" + 0.014*\"evidence\" + 0.014*\"statement\" + 0.014*\"attempt\" + '\n  '0.014*\"certification\" + 0.014*\"evening\" + 0.014*\"agency\" + 0.014*\"vote\" + '\n  '0.014*\"tip\" + 0.014*\"foreign\"'),\n (6,\n  '0.015*\"\\n'\n  '\\n'\n  ' \" + 0.014*\"evidence\" + 0.014*\"foreign\" + 0.014*\"vote\" + 0.014*\"effort\" + '\n  '0.014*\"american\" + 0.014*\"Krebs\" + 0.014*\"public\" + 0.014*\"Hillary\" + '\n  '0.014*\"official\"'),\n (7,\n  '0.014*\"\\n'\n  '\\n'\n  ' \" + 0.014*\"foreign\" + 0.014*\"vote\" + 0.014*\"evidence\" + 0.014*\"american\" + '\n  '0.014*\"Krebs\" + 0.014*\"effort\" + 0.014*\"change\" + 0.014*\"come\" + '\n  '0.014*\"day\"'),\n (8,\n  '0.014*\"foreign\" + 0.014*\"\\n'\n  '\\n'\n  ' \" + 0.014*\"vote\" + 0.014*\"effort\" + 0.014*\"evidence\" + 0.014*\"american\" + '\n  '0.014*\"Krebs\" + 0.014*\"evening\" + 0.014*\"Hillary\" + 0.014*\"defence\"'),\n (9,\n  '0.014*\"\\n'\n  '\\n'\n  ' \" + 0.014*\"government\" + 0.014*\"american\" + 0.014*\"counting\" + '\n  '0.014*\"evidence\" + 0.014*\"final\" + 0.014*\"actor\" + 0.014*\"foreign\" + '\n  '0.014*\"vote\" + 0.014*\"state\"')]\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(num_words=10)\n",
    "pprint(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}